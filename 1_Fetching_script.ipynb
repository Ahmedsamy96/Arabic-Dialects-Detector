{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the given Dataset of Target values with it's ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect\n",
       "0  1175358310087892992      IQ\n",
       "1  1175416117793349632      IQ\n",
       "2  1175450108898565888      IQ\n",
       "3  1175471073770573824      IQ\n",
       "4  1175496913145217024      IQ"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialict_df= pd.read_csv('2_given Dataset/dialect_dataset.csv')\n",
    "dialict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of rows of the given Dataset\n",
    "- This step's output will be used in the next cell to select the Number of iteration for reading the opposit text using POST method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458197"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialict_df['id'] = dialict_df['id'].astype(str)\n",
    "\n",
    "text_id = dialict_df[\"id\"].tolist()\n",
    "len(text_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the whole data using it's id\n",
    "- This is the main step for fetching the needed data. As this is a problem with POST method of rendering more than 1000 record, So I created a for loop iterate over the the whole data by it's id.\n",
    "- Each iteration retrieves a 1000 record in a dictionary and the next iterations output is been appended to the first dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n",
      "1 1000\n",
      "2 1000\n",
      "3 1000\n",
      "4 1000\n",
      "5 1000\n",
      "6 1000\n",
      "7 1000\n",
      "8 1000\n",
      "9 1000\n",
      "10 1000\n",
      "11 1000\n",
      "12 1000\n",
      "13 1000\n",
      "14 1000\n",
      "15 1000\n",
      "16 1000\n",
      "17 1000\n",
      "18 1000\n",
      "19 1000\n",
      "20 1000\n",
      "21 1000\n",
      "22 1000\n",
      "23 1000\n",
      "24 1000\n",
      "25 1000\n",
      "26 1000\n",
      "27 1000\n",
      "28 1000\n",
      "29 1000\n",
      "30 1000\n",
      "31 1000\n",
      "32 1000\n",
      "33 1000\n",
      "34 1000\n",
      "35 1000\n",
      "36 1000\n",
      "37 1000\n",
      "38 1000\n",
      "39 1000\n",
      "40 1000\n",
      "41 1000\n",
      "42 1000\n",
      "43 1000\n",
      "44 1000\n",
      "45 1000\n",
      "46 1000\n",
      "47 1000\n",
      "48 1000\n",
      "49 1000\n",
      "50 1000\n",
      "51 1000\n",
      "52 1000\n",
      "53 1000\n",
      "54 1000\n",
      "55 1000\n",
      "56 1000\n",
      "57 1000\n",
      "58 1000\n",
      "59 1000\n",
      "60 1000\n",
      "61 1000\n",
      "62 1000\n",
      "63 1000\n",
      "64 1000\n",
      "65 1000\n",
      "66 1000\n",
      "67 1000\n",
      "68 1000\n",
      "69 1000\n",
      "70 1000\n",
      "71 1000\n",
      "72 1000\n",
      "73 1000\n",
      "74 1000\n",
      "75 1000\n",
      "76 1000\n",
      "77 1000\n",
      "78 1000\n",
      "79 1000\n",
      "80 1000\n",
      "81 1000\n",
      "82 1000\n",
      "83 1000\n",
      "84 1000\n",
      "85 1000\n",
      "86 1000\n",
      "87 1000\n",
      "88 1000\n",
      "89 1000\n",
      "90 1000\n",
      "91 1000\n",
      "92 1000\n",
      "93 1000\n",
      "94 1000\n",
      "95 1000\n",
      "96 1000\n",
      "97 1000\n",
      "98 1000\n",
      "99 1000\n",
      "100 1000\n",
      "101 1000\n",
      "102 1000\n",
      "103 1000\n",
      "104 1000\n",
      "105 1000\n",
      "106 1000\n",
      "107 1000\n",
      "108 1000\n",
      "109 1000\n",
      "110 1000\n",
      "111 1000\n",
      "112 1000\n",
      "113 1000\n",
      "114 1000\n",
      "115 1000\n",
      "116 1000\n",
      "117 1000\n",
      "118 1000\n",
      "119 1000\n",
      "120 1000\n",
      "121 1000\n",
      "122 1000\n",
      "123 1000\n",
      "124 1000\n",
      "125 1000\n",
      "126 1000\n",
      "127 1000\n",
      "128 1000\n",
      "129 1000\n",
      "130 1000\n",
      "131 1000\n",
      "132 1000\n",
      "133 1000\n",
      "134 1000\n",
      "135 1000\n",
      "136 1000\n",
      "137 1000\n",
      "138 1000\n",
      "139 1000\n",
      "140 1000\n",
      "141 1000\n",
      "142 1000\n",
      "143 1000\n",
      "144 1000\n",
      "145 1000\n",
      "146 1000\n",
      "147 1000\n",
      "148 1000\n",
      "149 1000\n",
      "150 1000\n",
      "151 1000\n",
      "152 1000\n",
      "153 1000\n",
      "154 1000\n",
      "155 1000\n",
      "156 1000\n",
      "157 1000\n",
      "158 1000\n",
      "159 1000\n",
      "160 1000\n",
      "161 1000\n",
      "162 1000\n",
      "163 1000\n",
      "164 1000\n",
      "165 1000\n",
      "166 1000\n",
      "167 1000\n",
      "168 1000\n",
      "169 1000\n",
      "170 1000\n",
      "171 1000\n",
      "172 1000\n",
      "173 1000\n",
      "174 1000\n",
      "175 1000\n",
      "176 1000\n",
      "177 1000\n",
      "178 1000\n",
      "179 1000\n",
      "180 1000\n",
      "181 1000\n",
      "182 1000\n",
      "183 1000\n",
      "184 1000\n",
      "185 1000\n",
      "186 1000\n",
      "187 1000\n",
      "188 1000\n",
      "189 1000\n",
      "190 1000\n",
      "191 1000\n",
      "192 1000\n",
      "193 1000\n",
      "194 1000\n",
      "195 1000\n",
      "196 1000\n",
      "197 1000\n",
      "198 1000\n",
      "199 1000\n",
      "200 1000\n",
      "201 1000\n",
      "202 1000\n",
      "203 1000\n",
      "204 1000\n",
      "205 1000\n",
      "206 1000\n",
      "207 1000\n",
      "208 1000\n",
      "209 1000\n",
      "210 1000\n",
      "211 1000\n",
      "212 1000\n",
      "213 1000\n",
      "214 1000\n",
      "215 1000\n",
      "216 1000\n",
      "217 1000\n",
      "218 1000\n",
      "219 1000\n",
      "220 1000\n",
      "221 1000\n",
      "222 1000\n",
      "223 1000\n",
      "224 1000\n",
      "225 1000\n",
      "226 1000\n",
      "227 1000\n",
      "228 1000\n",
      "229 1000\n",
      "230 1000\n",
      "231 1000\n",
      "232 1000\n",
      "233 1000\n",
      "234 1000\n",
      "235 1000\n",
      "236 1000\n",
      "237 1000\n",
      "238 1000\n",
      "239 1000\n",
      "240 1000\n",
      "241 1000\n",
      "242 1000\n",
      "243 1000\n",
      "244 1000\n",
      "245 1000\n",
      "246 1000\n",
      "247 1000\n",
      "248 1000\n",
      "249 1000\n",
      "250 1000\n",
      "251 1000\n",
      "252 1000\n",
      "253 1000\n",
      "254 1000\n",
      "255 1000\n",
      "256 1000\n",
      "257 1000\n",
      "258 1000\n",
      "259 1000\n",
      "260 1000\n",
      "261 1000\n",
      "262 1000\n",
      "263 1000\n",
      "264 1000\n",
      "265 1000\n",
      "266 1000\n",
      "267 1000\n",
      "268 1000\n",
      "269 1000\n",
      "270 1000\n",
      "271 1000\n",
      "272 1000\n",
      "273 1000\n",
      "274 1000\n",
      "275 1000\n",
      "276 1000\n",
      "277 1000\n",
      "278 1000\n",
      "279 1000\n",
      "280 1000\n",
      "281 1000\n",
      "282 1000\n",
      "283 1000\n",
      "284 1000\n",
      "285 1000\n",
      "286 1000\n",
      "287 1000\n",
      "288 1000\n",
      "289 1000\n",
      "290 1000\n",
      "291 1000\n",
      "292 1000\n",
      "293 1000\n",
      "294 1000\n",
      "295 1000\n",
      "296 1000\n",
      "297 1000\n",
      "298 1000\n",
      "299 1000\n",
      "300 1000\n",
      "301 1000\n",
      "302 1000\n",
      "303 1000\n",
      "304 1000\n",
      "305 1000\n",
      "306 1000\n",
      "307 1000\n",
      "308 1000\n",
      "309 1000\n",
      "310 1000\n",
      "311 1000\n",
      "312 1000\n",
      "313 1000\n",
      "314 1000\n",
      "315 1000\n",
      "316 1000\n",
      "317 1000\n",
      "318 1000\n",
      "319 1000\n",
      "320 1000\n",
      "321 1000\n",
      "322 1000\n",
      "323 1000\n",
      "324 1000\n",
      "325 1000\n",
      "326 1000\n",
      "327 1000\n",
      "328 1000\n",
      "329 1000\n",
      "330 1000\n",
      "331 1000\n",
      "332 1000\n",
      "333 1000\n",
      "334 1000\n",
      "335 1000\n",
      "336 1000\n",
      "337 1000\n",
      "338 1000\n",
      "339 1000\n",
      "340 1000\n",
      "341 1000\n",
      "342 1000\n",
      "343 1000\n",
      "344 1000\n",
      "345 1000\n",
      "346 1000\n",
      "347 1000\n",
      "348 1000\n",
      "349 1000\n",
      "350 1000\n",
      "351 1000\n",
      "352 1000\n",
      "353 1000\n",
      "354 1000\n",
      "355 1000\n",
      "356 1000\n",
      "357 1000\n",
      "358 1000\n",
      "359 1000\n",
      "360 1000\n",
      "361 1000\n",
      "362 1000\n",
      "363 1000\n",
      "364 1000\n",
      "365 1000\n",
      "366 1000\n",
      "367 1000\n",
      "368 1000\n",
      "369 1000\n",
      "370 1000\n",
      "371 1000\n",
      "372 1000\n",
      "373 1000\n",
      "374 1000\n",
      "375 1000\n",
      "376 1000\n",
      "377 1000\n",
      "378 1000\n",
      "379 1000\n",
      "380 1000\n",
      "381 1000\n",
      "382 1000\n",
      "383 1000\n",
      "384 1000\n",
      "385 1000\n",
      "386 1000\n",
      "387 1000\n",
      "388 1000\n",
      "389 1000\n",
      "390 1000\n",
      "391 1000\n",
      "392 1000\n",
      "393 1000\n",
      "394 1000\n",
      "395 1000\n",
      "396 1000\n",
      "397 1000\n",
      "398 1000\n",
      "399 1000\n",
      "400 1000\n",
      "401 1000\n",
      "402 1000\n",
      "403 1000\n",
      "404 1000\n",
      "405 1000\n",
      "406 1000\n",
      "407 1000\n",
      "408 1000\n",
      "409 1000\n",
      "410 1000\n",
      "411 1000\n",
      "412 1000\n",
      "413 1000\n",
      "414 1000\n",
      "415 1000\n",
      "416 1000\n",
      "417 1000\n",
      "418 1000\n",
      "419 1000\n",
      "420 1000\n",
      "421 1000\n",
      "422 1000\n",
      "423 1000\n",
      "424 1000\n",
      "425 1000\n",
      "426 1000\n",
      "427 1000\n",
      "428 1000\n",
      "429 1000\n",
      "430 1000\n",
      "431 1000\n",
      "432 1000\n",
      "433 1000\n",
      "434 1000\n",
      "435 1000\n",
      "436 1000\n",
      "437 1000\n",
      "438 1000\n",
      "439 1000\n",
      "440 1000\n",
      "441 1000\n",
      "442 1000\n",
      "443 1000\n",
      "444 1000\n",
      "445 1000\n",
      "446 1000\n",
      "447 1000\n",
      "448 1000\n",
      "449 1000\n",
      "450 1000\n",
      "451 1000\n",
      "452 1000\n",
      "453 1000\n",
      "454 1000\n",
      "455 1000\n",
      "456 1000\n",
      "457 1000\n"
     ]
    }
   ],
   "source": [
    "All_data = {}\n",
    "for i in range(458000//1000):\n",
    "    text_data = dialict_df[\"id\"][i*1000:((i*1000)+1000)].tolist()\n",
    "    res = requests.post(url='https://recruitment.aimtechnologies.co/ai-tasks',json=text_data)\n",
    "    data = res.json()\n",
    "    print(i , len(data))\n",
    "    All_data.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458000\n"
     ]
    }
   ],
   "source": [
    "# Type number of All retieved text\n",
    "print(len(All_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this step i convert the dict of (id, Text) into a DataFrame to deal with it in easier way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(All_data.items(), columns=['id', 'Text'])\n",
    "text_col = df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the given dataset (is , dialect) to match the Fetched data, Then  Merge them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-885d6cce5273>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Text']= df['Text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1175358310087892992</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175416117793349632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175450108898565888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema مبين من كلامه خليجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1175471073770573824</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@HAIDER76128900 يسلملي مرورك وروحك الحلوه💐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1175496913145217024</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@hmo2406 وين هل الغيبه  اخ محمد 🌸🌺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1175668034146643968</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@Badi9595 @KanaanRema يااخي الإرهابي اذا كان ع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1175670153884983296</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@SarahNadhum90 @nUBNTdfVgACYQxV مطلبي يقدم است...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1175671762580856832</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema @Badi9595 خلص والله لعيونكم انا ما...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1175715664398561280</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@SalahAlarbawi يمكن سؤال فات الكثير اللي يصور ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1176019816072777728</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@Eng_alow91 @cb4LwpWrS1hT5lb @EdyCohen اولا ان...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1176068581487992832</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@kamal1277New والله هذا الموضوع جداً حساس ويحي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1176068868747538432</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@cb4LwpWrS1hT5lb لا ان شاء الله اخوه يجمعنه ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1176198561941413888</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@QSHRXxV36EfuNXV يسعد مساك سيد الحرف الحزين 🌷🙏🌹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1176199622412427264</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@3Obeidi ههههه عدوله گلبه ورم من عدنه .. گلك خ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1176460355939328000</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@0b9lxe0ZNEUlnQm يسلملي مرورك 🌺روعات تواصلك🌷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1176572872577474560</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@aaddssfr يسعد مساك بنت العم 🌸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1176608948671209472</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@ha___m___ed مااخذ اي بشر وحدي 😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1176877065473274112</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@kamal1277New اتركه فتره اذا ماسأل مايستحق اهت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1177172360455237632</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@sfer661 يأكلون بخيرنه ويهينون  موظفينه ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1177213425858109440</td>\n",
       "      <td>IQ</td>\n",
       "      <td>@QSHRXxV36EfuNXV عباله يرجع صدام حسين للحكم</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id dialect  \\\n",
       "0   1175358310087892992      IQ   \n",
       "1   1175416117793349632      IQ   \n",
       "2   1175450108898565888      IQ   \n",
       "3   1175471073770573824      IQ   \n",
       "4   1175496913145217024      IQ   \n",
       "5   1175668034146643968      IQ   \n",
       "6   1175670153884983296      IQ   \n",
       "7   1175671762580856832      IQ   \n",
       "8   1175715664398561280      IQ   \n",
       "9   1176019816072777728      IQ   \n",
       "10  1176068581487992832      IQ   \n",
       "11  1176068868747538432      IQ   \n",
       "12  1176198561941413888      IQ   \n",
       "13  1176199622412427264      IQ   \n",
       "14  1176460355939328000      IQ   \n",
       "15  1176572872577474560      IQ   \n",
       "16  1176608948671209472      IQ   \n",
       "17  1176877065473274112      IQ   \n",
       "18  1177172360455237632      IQ   \n",
       "19  1177213425858109440      IQ   \n",
       "\n",
       "                                                 Text  \n",
       "0    @Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .  \n",
       "1   @7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...  \n",
       "2                     @KanaanRema مبين من كلامه خليجي  \n",
       "3          @HAIDER76128900 يسلملي مرورك وروحك الحلوه💐  \n",
       "4                  @hmo2406 وين هل الغيبه  اخ محمد 🌸🌺  \n",
       "5   @Badi9595 @KanaanRema يااخي الإرهابي اذا كان ع...  \n",
       "6   @SarahNadhum90 @nUBNTdfVgACYQxV مطلبي يقدم است...  \n",
       "7   @KanaanRema @Badi9595 خلص والله لعيونكم انا ما...  \n",
       "8   @SalahAlarbawi يمكن سؤال فات الكثير اللي يصور ...  \n",
       "9   @Eng_alow91 @cb4LwpWrS1hT5lb @EdyCohen اولا ان...  \n",
       "10  @kamal1277New والله هذا الموضوع جداً حساس ويحي...  \n",
       "11  @cb4LwpWrS1hT5lb لا ان شاء الله اخوه يجمعنه ال...  \n",
       "12    @QSHRXxV36EfuNXV يسعد مساك سيد الحرف الحزين 🌷🙏🌹  \n",
       "13  @3Obeidi ههههه عدوله گلبه ورم من عدنه .. گلك خ...  \n",
       "14       @0b9lxe0ZNEUlnQm يسلملي مرورك 🌺روعات تواصلك🌷  \n",
       "15                     @aaddssfr يسعد مساك بنت العم 🌸  \n",
       "16                   @ha___m___ed مااخذ اي بشر وحدي 😂  \n",
       "17  @kamal1277New اتركه فتره اذا ماسأل مايستحق اهت...  \n",
       "18         @sfer661 يأكلون بخيرنه ويهينون  موظفينه ..  \n",
       "19        @QSHRXxV36EfuNXV عباله يرجع صدام حسين للحكم  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = dialict_df[0:458000]\n",
    "df2['Text']= df['Text']\n",
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458000, 3)\n"
     ]
    }
   ],
   "source": [
    "# The Final Created DataFrame shape\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the final output to be used in the Next step of the Task (Data Preprocessing)\n",
    "df2.to_csv('outputs/output_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
