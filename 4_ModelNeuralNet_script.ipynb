{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , LSTM ,Dropout ,SpatialDropout1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping ,  ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>حاب نضحك لكن رانا سيريو هاد اليومين</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ما تتخيلي السعادة بعد ما قريت الاسم وشوفت الصو...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ريتها ما تبلى الضحكه الله يبسطك على طول</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اللي كانت تحط الكورة تحت ملابسها ️وتسوي نفسها ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>القادسيهالكويت ممكن تردد القناة الناقلة</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166423</th>\n",
       "      <td>ماكرهناش يزيدو هاد الايموجي الخوت</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166424</th>\n",
       "      <td>تخيل وانت قاعد معا باتك ويقولك سامحني يا وليدي...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166425</th>\n",
       "      <td>ونحنا حدك قول الله</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166426</th>\n",
       "      <td>نمدح هيئة الكهربا في الشارجة</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166427</th>\n",
       "      <td>مالك خص اذا جتك السبه ردها بالمثل ولا تدخل حد ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166428 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  dialect\n",
       "0                     حاب نضحك لكن رانا سيريو هاد اليومين       13\n",
       "1       ما تتخيلي السعادة بعد ما قريت الاسم وشوفت الصو...       15\n",
       "2                 ريتها ما تبلى الضحكه الله يبسطك على طول        6\n",
       "3       اللي كانت تحط الكورة تحت ملابسها ️وتسوي نفسها ...       11\n",
       "4                 القادسيهالكويت ممكن تردد القناة الناقلة       16\n",
       "...                                                   ...      ...\n",
       "166423                  ماكرهناش يزيدو هاد الايموجي الخوت       16\n",
       "166424  تخيل وانت قاعد معا باتك ويقولك سامحني يا وليدي...        4\n",
       "166425                                 ونحنا حدك قول الله        7\n",
       "166426                       نمدح هيئة الكهربا في الشارجة        9\n",
       "166427  مالك خص اذا جتك السبه ردها بالمثل ولا تدخل حد ...        9\n",
       "\n",
       "[166428 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('outputs/output_3.csv')\n",
    "df = dataset.drop(columns=['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seting some parameters and creating the word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tokens are: 310985\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "emb_dim = 100\n",
    "batch_size = 256\n",
    "n_most_common_words = 80000\n",
    "max_len = 250\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['Text'].values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Unique Tokens are:\",len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the tensors to be input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor (166428, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['Text'].values)\n",
    "X = pad_sequences(X , maxlen=max_len)\n",
    "print(\"Shape of data tensor\",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 53280,   189,  5607],\n",
       "       [    0,     0,     0, ..., 31567,  2184,    13],\n",
       "       [    0,     0,     0, ..., 53282,     7,   198],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  5508,   499,     6],\n",
       "       [    0,     0,     0, ...,  2516,     3,  7659],\n",
       "       [    0,     0,     0, ...,   923,  2005,  2998]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor (166428, 18)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['dialect']).values\n",
    "print(\"Shape of label tensor\",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,  test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149785, 250) (16643, 250) (149785, 18) (16643, 18)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 250, 100)          8000100   \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 250, 100)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                1818      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,082,318\n",
      "Trainable params: 8,082,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_most_common_words+1,emb_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(100,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(18,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy' , optimizer='adam' ,metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting some callbacks like early stoping and auto saving best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks=[  EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 2,verbose = 1,restore_best_weights = True) ,\n",
    "                ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5',monitor='val_loss',mode='min',save_best_only=True,verbose=1)  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 2.2561 - accuracy: 0.2701\n",
      "Epoch 00001: val_loss improved from inf to 1.88547, saving model to model.01-1.89.h5\n",
      "1171/1171 [==============================] - 4245s 4s/step - loss: 2.2561 - accuracy: 0.2701 - val_loss: 1.8855 - val_accuracy: 0.3988\n",
      "Epoch 2/5\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 1.6313 - accuracy: 0.4781\n",
      "Epoch 00002: val_loss improved from 1.88547 to 1.73899, saving model to model.02-1.74.h5\n",
      "1171/1171 [==============================] - 4293s 4s/step - loss: 1.6313 - accuracy: 0.4781 - val_loss: 1.7390 - val_accuracy: 0.4542\n",
      "Epoch 3/5\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 1.2729 - accuracy: 0.5986\n",
      "Epoch 00003: val_loss did not improve from 1.73899\n",
      "1171/1171 [==============================] - 4382s 4s/step - loss: 1.2729 - accuracy: 0.5986 - val_loss: 1.7533 - val_accuracy: 0.4740\n",
      "Epoch 4/5\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 1.0230 - accuracy: 0.6811Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.73899\n",
      "1171/1171 [==============================] - 4778s 4s/step - loss: 1.0230 - accuracy: 0.6811 - val_loss: 1.8657 - val_accuracy: 0.4727\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=128, callbacks=my_callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "model.save(\"outputs/my_h5_model.h5\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "- Here you can see the model accuracy is not good enough but you have to know the the model just trained on only 5 epochs, But each epoch take more than 2 hours because thne amount of data was not small, so i want to say that the model can give better accuracy if it was trained on more number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521/521 [==============================] - 57s 110ms/step - loss: 1.7390 - accuracy: 0.4542\n",
      "Test set\n",
      "  Loss: 1.739\n",
      "  Accuracy: 0.454\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on a given text\n",
    "- Although the model accuracy was not good but when it take easy recognizable text it predict it very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4054772e-03 1.9003147e-04 4.7690082e-05 1.8438566e-02 6.7165340e-05\n",
      "  5.8164464e-05 1.5003608e-04 1.4943248e-04 9.9206969e-05 3.9845829e-05\n",
      "  3.7252918e-05 1.8293475e-04 2.0087668e-01 3.6764908e-05 6.1633380e-04\n",
      "  7.5468510e-01 8.6046719e-05 2.1833224e-02]] MA\n"
     ]
    }
   ],
   "source": [
    "txt = [\"راه صعيب عليك\"]\n",
    "seq = tokenizer.texts_to_sequences(txt)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "labels = ['EG'    ,\n",
    "'PL'    ,\n",
    "'KW'    ,\n",
    "'LY'    ,\n",
    "'QA'    ,\n",
    "'JO'    ,\n",
    "'LB'    ,\n",
    "'SA'    ,\n",
    "'AE'    ,\n",
    "'BH'    ,\n",
    "'OM'    ,\n",
    "'SY'    ,\n",
    "'DZ'    ,\n",
    "'IQ'    ,\n",
    "'SD'    ,\n",
    "'MA'    ,\n",
    "'YE'    , \n",
    "'TN']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
